# HDFS问题记录

### 1、Cannot obtain block length for LocatedBlock故障分析和解决

## **一.问题背景**

采用Flink进行数据实时写入HDFS时，由于Flink任务异常退出后，在HDFS上正在写入的文件是一个隐藏文件，如果cat这个隐藏文件会报Cannot obtain block length for LocatedBlock异常

## **二.解决过程**

1.使用用fsck检查一下，可以具体到指定的hdfs路径,

hdfs fsck /

检查完打印结果没有发现任何异常，没有发现损坏或者Corrupt的block

2.那么加上参数 【 –openforwrite】， 检查处于打开写入状态的文件， 可以查到该隐藏文件是处于打开写入状态。

hdfs fsck / –openforwrite

因此无法cat和get，这里的”Cannot obtain block length for LocatedBlock”应该是当前这些文件处于写入状态并且未关闭，无法与对应的datanode通信来成功标识其block长度.

问题：Flink异常退出为什么会导致写入的hdfs文件没有被正常close，状态不一致随后无法正常访问。

3.推断:HDFS文件租约的原因：未释放

了解过HDFS租约.....

客户端在每次读写HDFS文件的时候获取租约对文件进行读写，文件读取完毕了，然后再释放此租约.文件状态就是关闭的了。

Flink对hdfs文件写入，由于Flink异常退出，因此最后文件没有写完，那么租约没释放导致的。

4.恢复租约

通过hdfs恢复租约命令， close掉文件， 如下

hdfs debug recoverLease -path <path-of-the-file> -retries <retry times>

ok，执行完命令后，这个隐藏文件可以正常cat，顺利显示内容。

 