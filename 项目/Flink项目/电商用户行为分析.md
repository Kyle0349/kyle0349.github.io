# 电商用户行为分析

> 使用flink分析用户行为数据

# 1 电商用户行为分析概述

## 1.1 统计分析

![flink_project_base_01](https://tva1.sinaimg.cn/large/008i3skNgy1gxmbbn1qnyj31cr0u00vb.jpg)

1. 点击、浏览
2. 热门商品、近期热门商品、分类热门商品、流量统计

## 1.2 偏好统计

1. 收藏、喜欢、评分、打标签
2. 用户画像，推荐列表（结合特征工程和机器学习算法）

## 1.3 风险控制

1. 下订单、支付、登录
2. 刷单监控，订单失效监控，恶意登录（短时间内频繁登录失败）监控

# 2 模块设计

## 2.1 实现功能

### 2.1.1 实习统计分析

1. 实时热门商品统计
2. 实时热门页面流量统计
3. 实时访问流量统计
4.  APP 市场推广统计
5. 页面广告点击量统计

### 2.1.2 业务流程及风险控制

1. 页面广告黑名单过滤
2. 恶意登录监控
3. 订单支付失效监控
4. 支付实时对账

# 3 数据源解析

## 3.1 数据结构 

### 3.1.1 UserBehavior

| **字段名** | **数据类型** | **说明**                                       |
| ---------- | ------------ | ---------------------------------------------- |
| userId     | Long         | 加密后的用户ID                                 |
| itemId     | Long         | 加密后的商品ID                                 |
| categoryId | Int          | 加密后的商品所属类别ID                         |
| behavior   | String       | 用户行为类型，包括(‘pv’, ‘buy’, ‘cart’, ‘fav’) |
| timestamp  | Long         | 行为发生的时间戳，单位秒                       |
|            |              |                                                |

### 3.1.2 ApacheLogEvent

| **字段名** | **数据类型** | **说明**                     |
| ---------- | ------------ | ---------------------------- |
| ip         | String       | 访问的 IP                    |
| userId     | Long         | 访问的 user ID               |
| eventTime  | Long         | 访问时间                     |
| method     | String       | 访问方法 GET/POST/PUT/DELETE |
| url        | String       | 访问的 url                   |
|            |              |                              |

# 4 项目

## 4.1 模块

- 实时热门商品统计
- 实时流量统计
- 市场营销分析
- 恶意登录监控
- 订单支付实时监控

## 4.2 实现 - 实时热门商品统计

### 4.2.1 基本需求

	1. 统计近1小时内的热门商品，每5分钟更新一次
	2. 热门度用浏览次数（“PV”）来衡量

### 4.2.2 解决思路

1. 在所有的用户行为数据中，过滤出浏览（“PV”）行为进行统计

2. 构建滑动窗口，窗口长度为1小时，滑动距离为5分钟

   ![flink_project_hot_cal_01](https://tva1.sinaimg.cn/large/008i3skNgy1gxmcaaz3u3j30o80gtmyd.jpg)









# 5 代码实现

## 5.1 热门商品（事件时间有序）

### 5.1.1代码

1. 读取文件数据



2. 读取kafka数据

   ~~~java
   package com.kyle.hotitems_analysis;
   
   import com.kyle.hotitems_analysis.beans.ItemViewCount;
   import com.kyle.hotitems_analysis.beans.UserBehavior;
   import org.apache.commons.compress.utils.Lists;
   import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
   import org.apache.flink.api.common.eventtime.WatermarkStrategy;
   import org.apache.flink.api.common.functions.AggregateFunction;
   import org.apache.flink.api.common.functions.MapFunction;
   import org.apache.flink.api.common.serialization.SimpleStringSchema;
   import org.apache.flink.api.common.state.ListState;
   import org.apache.flink.api.common.state.ListStateDescriptor;
   import org.apache.flink.api.java.tuple.Tuple;
   import org.apache.flink.configuration.Configuration;
   import org.apache.flink.streaming.api.datastream.DataStreamSource;
   import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
   import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
   import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
   import org.apache.flink.streaming.api.functions.windowing.WindowFunction;
   import org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows;
   import org.apache.flink.streaming.api.windowing.time.Time;
   import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
   import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
   import org.apache.flink.util.Collector;
   import scala.collection.Iterable;
   
   import java.sql.Timestamp;
   import java.util.ArrayList;
   import java.util.Comparator;
   import java.util.Properties;
   
   /**
    * @author kyle on 2022-01-03 11:43 上午
    */
   public class HotItemsNew {
   
      public static void main(String[] args) throws Exception {
   
   
         // 1. 获取 flink 流运行环境
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
         env.setParallelism(1);
   
   
         // 2. 读取数据
   //      String filePath = "/Users/kyle/Documents/kyle/project/flink/FlinkUserBehavior/HotItemAnalysis/src/main/resources/UserBehavior.csv";
   //      DataStreamSource<String> inputStream = env.readTextFile(filePath);
   
         // 读取kafka数据
         Properties properties = new Properties();
         properties.setProperty("bootstrap.servers", "192.168.2.113:9092");
         properties.setProperty("group.id", "hot-item-analysis");
         String inputTopic = "hot_item";
         FlinkKafkaConsumer<String> stringFlinkKafkaConsumer = new FlinkKafkaConsumer<>(inputTopic, new SimpleStringSchema(), properties);
   
         DataStreamSource<String> inputStream = env.addSource(stringFlinkKafkaConsumer);
   
   
         // 3. 将数据流格式化为 POJO 流，并打水印
         SingleOutputStreamOperator<UserBehavior> dataStream = inputStream
                 .filter(data -> !"".equals(data))
                 .map(new MapFunction<String, UserBehavior>() {
            @Override
            public UserBehavior map(String value) throws Exception {
               String[] fields = value.split(",");
               return new UserBehavior(Long.parseLong(fields[0]),
                       Long.parseLong(fields[1]),
                       Integer.parseInt(fields[2]),
                       fields[3],
                       Long.parseLong(fields[4]));
            }
         })
                 .assignTimestampsAndWatermarks(WatermarkStrategy.<UserBehavior>forMonotonousTimestamps()
                         .withTimestampAssigner(new SerializableTimestampAssigner<UserBehavior>() {
                            @Override
                            public long extractTimestamp(UserBehavior element, long recordTimestamp) {
                               return element.getTimestamp() * 1000L;
                            }
                         }));
   
         // 4. 开窗聚合，
         // 4.1 筛选行为 是 pv的记录
         // 4.2 统计每个窗口内各个商品出现的次数
         SingleOutputStreamOperator<ItemViewCount> windowStream = dataStream.filter(data -> "pv".equals(data.getBehavior()))
                 .keyBy("itemId")
                 .window(SlidingEventTimeWindows.of(Time.hours(1), Time.minutes(5)))
                 .aggregate(new ItemCountAgg(), new WindowItemCountResult());
   
   
         // 5. 收集同一窗口的所有商品count数据，排序输出top n
         SingleOutputStreamOperator<String> topNStream = windowStream.keyBy("windowEnd")
                 .process(new TopNHotItems(5));
   
   
   
   
   
         topNStream.print();
   
         env.execute();
   
   
   
   
      }
   
      // 实现自定义增量聚合函数
      // 聚合函数 AggregateFunction 能拿到的信息很有限，需要更多窗口信息时，需要配合windowFunction
      public static class ItemCountAgg implements AggregateFunction<UserBehavior, Long, Long>{
   
         @Override
         public Long createAccumulator() {
            return 0L;
         }
   
         @Override
         public Long add(UserBehavior value, Long accumulator) {
            return accumulator + 1;
         }
   
         @Override
         public Long getResult(Long accumulator) {
            return accumulator;
         }
   
         @Override
         public Long merge(Long a, Long b) {
            return a + b;
         }
      }
   
      // 定义一个窗口函数,
      // 窗口函数可以拿到窗口的信息, 比如窗口的开始时间和结束时间
      public static class WindowItemCountResult implements WindowFunction<Long, ItemViewCount, Tuple, TimeWindow> {
   
         @Override
         public void apply(Tuple tuple, TimeWindow window, java.lang.Iterable<Long> input, Collector<ItemViewCount> out) throws Exception {
            Long itemId = tuple.getField(0);
   
            long windowEnd = window.getEnd();
            Long count = input.iterator().next();
            out.collect(new ItemViewCount(itemId, windowEnd, count));
   
         }
      }
   
   
      // 实现自定义keyedProcessFunction
      public static class TopNHotItems extends KeyedProcessFunction<Tuple, ItemViewCount, String>{
   
         // 定义属性 topN 的大小
         private Integer topSize;
   
         public TopNHotItems(Integer topSize) {
            this.topSize = topSize;
         }
   
         // 定义列表状态， 保存当前窗口内所有输出的ItemViewCount
         ListState<ItemViewCount> itemViewCountListState;
   
         @Override
         public void open(Configuration parameters) throws Exception {
            itemViewCountListState = getRuntimeContext()
                    .getListState(new ListStateDescriptor<ItemViewCount>("item-view-count-list", ItemViewCount.class));
         }
   
         @Override
         public void processElement(ItemViewCount value, Context ctx, Collector<String> out) throws Exception {
            // 每来一条数据， 存入list中， 并注册定时器
            itemViewCountListState.add(value);
            // 注册定时器
            ctx.timerService().registerEventTimeTimer(value.getWindowEnd() + 1);
         }
   
         @Override
         public void onTimer(long timestamp, OnTimerContext ctx, Collector<String> out) throws Exception {
            // 定时器触发，当前已收集到所有数据， 排序输出
            ArrayList<ItemViewCount> itemViewCounts = Lists.newArrayList(itemViewCountListState.get().iterator());
   
            itemViewCounts.sort(new Comparator<ItemViewCount>() {
               @Override
               public int compare(ItemViewCount o1, ItemViewCount o2) {
                  return o2.getCount().intValue() - o1.getCount().intValue();
               }
            });
   
            // 将排名信息格式化成String， 输出打印
            StringBuilder resultBuilder = new StringBuilder();
            resultBuilder.append("=============================\n");
            resultBuilder.append("窗口结束时间： ").append(new Timestamp(timestamp - 1)).append("\n");
   
            //遍历列表取 top N
            for(int  i = 0; i < Math.min(topSize, itemViewCounts.size()); i++){
               ItemViewCount itemViewCount = itemViewCounts.get(i);
               resultBuilder.append("NO ").append(i+1)
                       .append(" 商品 = ").append(itemViewCount.getItemId())
                       .append(" 热门度 = ").append(itemViewCount.getCount())
                       .append("\n");
   
            }
   
            resultBuilder.append("===========================\n");
   
            // 控制输出频率
            Thread.sleep(1000L);
   
            out.collect(resultBuilder.toString());
   
         }
      }
   
   ~~~

   ~~~java
   // 测试数据
   >543462,1715,1464116,pv,1511658000
   >662867,2244074,1575622,pv,1511658060
   >561558,3611281,965809,pv,1511658120
   >894923,1715,1879194,pv,1511658180
   >834377,2244074,3738615,pv,1511658240
   >625915,3611281,570735,pv,1511658300
   >625915,3611281,570735,pv,1511658301	// 第一次输出打印
   >
   >
   >578814,1715,982926,pv,1511658330
   >873335,1256540,1451783,pv,1511658540
   >429984,2244074,2355072,pv,1511658600
   >429984,2244074,2355072,pv,1511658601	// 第二次输出打印
   >
   >
   >937166,1715,2355072,pv,1511661600	// 第三次输出打印
   >
   >
   >937166,1715,2355072,pv,1511661601	// 第四次输出打印
   >
   
     
   // 输出打印
   	// 第一次输出打印 开始
   =============================
   窗口结束时间： 2017-11-26 09:05:00.0
   NO 1 商品 = 1715 热门度 = 2
   NO 2 商品 = 2244074 热门度 = 2
   NO 3 商品 = 3611281 热门度 = 1
   ===========================
     // 第一次输出打印 结束
   
     // 第二次输出打印 开始
   =============================
   窗口结束时间： 2017-11-26 09:10:00.0
   NO 1 商品 = 3611281 热门度 = 3
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 2244074 热门度 = 2
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
     // 第二次输出打印 结束
     
     // 第三次输出打印 开始
   =============================
   窗口结束时间： 2017-11-26 09:15:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 3611281 热门度 = 3
   NO 3 商品 = 1715 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:20:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 3611281 热门度 = 3
   NO 3 商品 = 1715 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:25:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 3611281 热门度 = 3
   NO 3 商品 = 1715 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:30:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 3611281 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:35:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 3611281 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:40:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 3611281 热门度 = 3
   NO 3 商品 = 1715 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:45:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 3611281 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:50:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 3611281 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
   
   =============================
   窗口结束时间： 2017-11-26 09:55:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 3611281 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
     // 第三次输出打印 结束
   
     // 第四次输出打印 开始
   =============================
   窗口结束时间： 2017-11-26 10:00:00.0
   NO 1 商品 = 2244074 热门度 = 4
   NO 2 商品 = 1715 热门度 = 3
   NO 3 商品 = 3611281 热门度 = 3
   NO 4 商品 = 1256540 热门度 = 1
   ===========================
     // 第四次输出打印 结束
   
   
   ~~~

   

## 5.2 实时热门页面统计（事件时间乱序）

### 5.2.1 代码(乱序数据没有处理的很好)

~~~java
package com.kyle.networkflow_analysis;

import com.kyle.networkflow_analysis.bean.ApacheLogEvent;
import com.kyle.networkflow_analysis.bean.PageViewCount;
import com.sun.org.apache.bcel.internal.generic.DADD;
import org.apache.commons.compress.utils.Lists;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.api.common.state.ListState;
import org.apache.flink.api.common.state.ListStateDescriptor;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.streaming.api.functions.windowing.WindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.util.Collector;
import org.apache.logging.log4j.util.Strings;
import scala.collection.Iterable;

import java.net.URL;
import java.sql.Timestamp;
import java.text.SimpleDateFormat;
import java.time.Duration;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.Properties;
import java.util.regex.Pattern;

/**
 * @author kyle on 2022-01-07 8:03 上午
 * 实时热门页面统计
 */
public class HotPages {

   public static void main(String[] args) throws Exception {

      // 1. 获取flink stream环境
      StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
      env.setParallelism(1);

      // 2. 读取文件， 转换成POJO
//      URL resource = HotPages.class.getResource("/apache.log");
//      DataStreamSource<String> inputStream = env.readTextFile(resource.getPath());

      // 从kafka读取数据
      Properties properties = new Properties();
      properties.setProperty("bootstrap.servers", "192.168.2.113:9092");
      properties.setProperty("group.id", "flink-hot-pages");
      String topic = "hot_pages";

      FlinkKafkaConsumer<String> stringFlinkKafkaConsumer = new FlinkKafkaConsumer<>(topic, new SimpleStringSchema(), properties);
      DataStreamSource<String> inputStream = env.addSource(stringFlinkKafkaConsumer);


      // 3. 提取时间戳和分配watermark
      SingleOutputStreamOperator<ApacheLogEvent> dataStream = inputStream
              .filter(Strings::isNotBlank)
              .map(line -> {
         String[] fields = line.split(" ");
         SimpleDateFormat simpleDateFormat = new SimpleDateFormat("dd/MM/yyyy:HH:mm:ss");
         Long timestamp = simpleDateFormat.parse(fields[3]).getTime();
         return new ApacheLogEvent(fields[0], fields[1], timestamp, fields[5], fields[6]);
      })
              .assignTimestampsAndWatermarks(WatermarkStrategy.<ApacheLogEvent>forBoundedOutOfOrderness(Duration.ofSeconds(1))
              .withTimestampAssigner(new SerializableTimestampAssigner<ApacheLogEvent>() {
                 @Override
                 public long extractTimestamp(ApacheLogEvent element, long recordTimestamp) {
                    return element.getTimestamp();
                 }
              }));

      dataStream.print("data");

      // 4. 分组开窗聚合
      SingleOutputStreamOperator<PageViewCount> windowAggStream = dataStream
              .filter(data -> "GET".equals(data.getMethod()))   // 过滤get请求
              .filter(data ->{
                 String regex = "^((?!\\.(css|js|png|ico)$).)*$";
                 return Pattern.matches(regex, data.getUrl());
              })
              .keyBy(ApacheLogEvent::getUrl) // 根据url分组
              .window(SlidingEventTimeWindows.of(Time.minutes(10), Time.seconds(5)))
              .allowedLateness(Time.minutes(1))
              .aggregate(new PageCountAgg(), new PageCountResult());

      windowAggStream.print("agg");


      SingleOutputStreamOperator<String> resultStream = windowAggStream.keyBy(PageViewCount::getWindowEnd).process(new TopNHotPages(5));


      resultStream.print();

      env.execute();


   }




   // 实现自定义聚合函数
   public static class PageCountAgg implements AggregateFunction<ApacheLogEvent, Long, Long>{

      @Override
      public Long createAccumulator() {
         return 0L;
      }

      @Override
      public Long add(ApacheLogEvent value, Long accumulator) {
         return accumulator + 1;
      }

      @Override
      public Long getResult(Long accumulator) {
         return accumulator;
      }

      @Override
      public Long merge(Long a, Long b) {
         return a+b;
      }
   }


   // 实现自定义的窗口函数
   public static class PageCountResult implements WindowFunction<Long, PageViewCount, String, TimeWindow> {

      @Override
      public void apply(String url, TimeWindow window, java.lang.Iterable<Long> input, Collector<PageViewCount> out) throws Exception {
         out.collect(new PageViewCount(url, window.getEnd(), input.iterator().next()));
      }
   }


   // 实现自定义的处理函数
   public static class TopNHotPages extends KeyedProcessFunction<Long, PageViewCount, String>{

      private Integer topSize;

      public TopNHotPages(Integer topSize) {
         this.topSize = topSize;
      }

      ListState<PageViewCount> pageViewCountListState;

      @Override
      public void open(Configuration parameters) throws Exception {
         pageViewCountListState = getRuntimeContext().getListState(new ListStateDescriptor<PageViewCount>("page-view-count-state", PageViewCount.class));

      }

      @Override
      public void processElement(PageViewCount value, Context ctx, Collector<String> out) throws Exception {
         pageViewCountListState.add(value);
         ctx.timerService().registerEventTimeTimer(value.getWindowEnd() + 1);
      }

      @Override
      public void onTimer(long timestamp, OnTimerContext ctx, Collector<String> out) throws Exception {
         ArrayList<PageViewCount> pageViewCounts = Lists.newArrayList(pageViewCountListState.get().iterator());

         pageViewCounts.sort(new Comparator<PageViewCount>() {
            @Override
            public int compare(PageViewCount o1, PageViewCount o2) {
               if(o1.getCount() > o2.getCount()){
                  return -1;
               }else if (o1.getCount() < o2.getCount()){
                  return 1;
               }else {
                  return 0;
               }
            }
         });


         // 将排名信息格式化成String， 输出打印
         StringBuilder resultBuilder = new StringBuilder();
         resultBuilder.append("=============================\n");
         resultBuilder.append("窗口结束时间： ").append(new Timestamp(timestamp - 1)).append("\n");

         //遍历列表取 top N
         for(int  i = 0; i < Math.min(topSize, pageViewCounts.size()); i++){
            PageViewCount pageViewCount = pageViewCounts.get(i);
            resultBuilder.append("NO ").append(i+1)
                    .append(" 页面url = ").append(pageViewCount.getUrl())
                    .append(" 浏览量 = ").append(pageViewCount.getCount())
                    .append("\n");

         }

         resultBuilder.append("===========================\n");

         // 控制输出频率
         Thread.sleep(1000L);

         out.collect(resultBuilder.toString());


      }
   }


}

~~~

~~~java
// 测试数据， 一条条输入kafka
83.149.9.216 - - 17/05/2015:10:25:49 +0000 GET /presentations
83.149.9.216 - - 17/05/2015:10:25:50 +0000 GET /presentations
83.149.9.216 - - 17/05/2015:10:25:51 +0000 GET /presentations
83.149.9.216 - - 17/05/2015:10:25:52 +0000 GET /presentations
83.149.9.216 - - 17/05/2015:10:25:55 +0000 GET /presentations
83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presentations
83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presen
83.149.9.216 - - 17/05/2015:10:25:57 +0000 GET /presen
83.149.9.216 - - 17/05/2015:10:26:01 +0000 GET /
83.149.9.216 - - 17/05/2015:10:26:02 +0000 GET /pre
83.149.9.216 - - 17/05/2015:10:25:46 +0000 GET /presentations // 乱序： 迟到数据
83.149.9.216 - - 17/05/2015:10:26:03 +0000 GET /pre

// 整合输入和输出，说明处理过程
// 设置的watermark是1秒延迟
// 设置窗口允许延迟1分钟
// 滑动窗口长度是10min，滑动步长是5秒， 即每5秒统计前10分钟的网页浏览量
// 定时器延迟1毫秒
  
>
>83.149.9.216 - - 17/05/2015:10:25:49 +0000 GET /presentations
> 17/05/2015:10:25:49 属于 [10:15:50,10:25:50)窗口
> watermark = 1431829549000 - 1 = 1431829548999 
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829549000, method='GET', url='/presentations'}

>
>83.149.9.216 - - 17/05/2015:10:25:50 +0000 GET /presentations
> 17/05/2015:10:25:50 属于 [10:15:55,10:25:55)窗口
> watermark = 1431829550000 - 1 = 1431829549999 
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829550000, method='GET', url='/presentations'}

>
>83.149.9.216 - - 17/05/2015:10:25:51 +0000 GET /presentations
> 17/05/2015:10:25:51 属于 [10:15:55,10:25:55)窗口
> watermark = 1431829551000 - 1 = 1431829550999  大于 1431829550000， 触发窗口计算， 所以有agg输出
> 排行榜没有打印， 因为定时器有1毫秒延迟， 需要下一个时间才会打印
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829551000, method='GET', url='/presentations'}
	agg> PageViewCount{url='/presentations', windowEnd=1431829550000, count=1}

>                          
>83.149.9.216 - - 17/05/2015:10:25:52 +0000 GET /presentations
> 17/05/2015:10:25:52 属于 [10:15:55,10:25:55)窗口
> watermark = 1431829552000 - 1 = 1431829551999 
> 输出了 10:25:50.0 （1431829550000）的排行榜
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829552000, method='GET', url='/presentations'}
  =============================
  窗口结束时间： 2015-05-17 10:25:50.0
  NO 1 页面url = /presentations 浏览量 = 1
  ===========================

>
>83.149.9.216 - - 17/05/2015:10:25:55 +0000 GET /presentations
> 17/05/2015:10:25:55 属于 [10:16:00,10:26:00)窗口
> watermark = 1431829555000 - 1 = 1431829554999 
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829555000, method='GET', url='/presentations'}

>
>83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presentations
> 17/05/2015:10:25:56 属于 [10:16:00,10:26:00)窗口
> watermark = 1431829556000 - 1 = 1431829555999   大于 1431829555000， 触发窗口计算， 所以有agg输出
> 排行榜没有打印， 因为定时器有1毫秒延迟， 需要下一个时间才会打印
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829556000, method='GET', url='/presentations'}
	agg> PageViewCount{url='/presentations', windowEnd=1431829555000, count=4}

>

>83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presen
> 17/05/2015:10:25:56 属于 [10:16:00,10:26:00)窗口
> watermark = 1431829556000 - 1 = 1431829555999   watermark没有发生变化
> 因为watermark没有发生变化， 事件时间还没来到1毫秒延迟的时间， 排行榜仍然没有打印， 因为定时器有1毫秒延迟， 需要下一个时间才会打印
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829556000, method='GET', url='/presen'}
        
>

>83.149.9.216 - - 17/05/2015:10:25:57 +0000 GET /presen
> 17/05/2015:10:25:57 属于 [10:16:00,10:26:00)窗口
> watermark = 1431829557000 - 1 = 1431829556999 
> 输出 10:25:55.0（1431829555000） 的排行榜
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829557000, method='GET', url='/presen'}
  =============================
  窗口结束时间： 2015-05-17 10:25:55.0
  NO 1 页面url = /presentations 浏览量 = 4
  ===========================

>
>83.149.9.216 - - 17/05/2015:10:26:01 +0000 GET /
> 17/05/2015:10:26:01 属于 [10:16:05,10:26:05)窗口
> watermark = 1431829561000 - 1 = 1431829560999 大于 1431829560000， 触发窗口计算，所以有agg输出
> 排行榜没有打印， 因为定时器有1毫秒延迟， 需要下一个时间才会打印
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829561000, method='GET', url='/'}
  agg> PageViewCount{url='/presentations', windowEnd=1431829560000, count=6}
  agg> PageViewCount{url='/presen', windowEnd=1431829560000, count=2}

>
>83.149.9.216 - - 17/05/2015:10:26:02 +0000 GET /pre
> 17/05/2015:10:26:02 属于 [10:16:05,10:26:05)窗口
> watermark = 1431829562000 - 1 = 1431829561999 
> 输出 10:26:00.0（1431829560000） 的排行榜
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829562000, method='GET', url='/pre'}
  =============================
  窗口结束时间： 2015-05-17 10:26:00.0
  NO 1 页面url = /presentations 浏览量 = 6
  NO 2 页面url = /presen 浏览量 = 2
  ===========================

                          
> // 乱序：迟到记录
>83.149.9.216 - - 17/05/2015:10:25:46 +0000 GET /presentations
> 17/05/2015:10:25:46 属于 [10:15:50,10:25:50)窗口
> watermark = 1431829546000 - 1 = 1431829545999 < 1431829561999, watermark 保持 1431829561999
> 因为设置有窗口允许延迟1分钟， 所以前面3个已经计算输出的窗口还没有关闭，
> 同时因为窗口长度设置为10min， 17/05/2015:10:25:46， 这条记录横跨了前面3个窗口， 所以3个窗口的数据都更新输出一次agg
> 排行榜没有打印， 因为定时器有1毫秒延迟， 需要下一个时间才会打印
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829546000, method='GET', url='/presentations'}
  agg> PageViewCount{url='/presentations', windowEnd=1431829560000, count=7}
  agg> PageViewCount{url='/presentations', windowEnd=1431829555000, count=5}
  agg> PageViewCount{url='/presentations', windowEnd=1431829550000, count=2}

                          
                          
>
>83.149.9.216 - - 17/05/2015:10:26:03 +0000 GET /pre
> 17/05/2015:10:26:03 属于 [10:16:05,10:26:05)窗口
> watermark = 1431829563000 - 1 = 1431829562999 
> watermark 更新了， 输出上面统计的3个窗口更新的数据，
> 但是排行榜输出的数据异常，相同的url出现了两个排行， 
> 原因是窗口计算完成一次后， 排行榜的lastSate记住了一次数据，延迟数据到来后，又计算了一次，在listState中有增加了1条记录。 // 需要继续优化代码处理
                          
  data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829563000, method='GET', url='/pre'}
  =============================
  窗口结束时间： 2015-05-17 10:25:50.0
  NO 1 页面url = /presentations 浏览量 = 2
  NO 2 页面url = /presentations 浏览量 = 1
  ===========================

  =============================
  窗口结束时间： 2015-05-17 10:25:55.0
  NO 1 页面url = /presentations 浏览量 = 5
  NO 2 页面url = /presentations 浏览量 = 4
  ===========================

  =============================
  窗口结束时间： 2015-05-17 10:26:00.0
  NO 1 页面url = /presentations 浏览量 = 7
  NO 2 页面url = /presentations 浏览量 = 6
  NO 3 页面url = /presen 浏览量 = 2
  ===========================
>



~~~



### 5.2.2 代码（乱序数据处理代码改进）

1. 5.2.1代码中的问题是： 在延迟的乱序数据到来后，由于相同的key的数据前面已经计算输出到了榜单，乱序数据来后，榜单已存在的数据没有被清除，就会出现旧的数据仍然留在榜单上， 和新统计的数据并存。
2. 

~~~java
package com.kyle.networkflow_analysis;

import com.kyle.networkflow_analysis.bean.ApacheLogEvent;
import com.kyle.networkflow_analysis.bean.PageViewCount;
import org.apache.commons.compress.utils.Lists;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.functions.AggregateFunction;
import org.apache.flink.api.common.serialization.SimpleStringSchema;
import org.apache.flink.api.common.state.ListState;
import org.apache.flink.api.common.state.ListStateDescriptor;
import org.apache.flink.api.common.state.MapState;
import org.apache.flink.api.common.state.MapStateDescriptor;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.datastream.DataStreamSource;
import org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.streaming.api.functions.windowing.WindowFunction;
import org.apache.flink.streaming.api.windowing.assigners.SlidingEventTimeWindows;
import org.apache.flink.streaming.api.windowing.time.Time;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;
import org.apache.flink.util.Collector;
import org.apache.logging.log4j.util.Strings;

import java.sql.Timestamp;
import java.text.SimpleDateFormat;
import java.time.Duration;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.Map;
import java.util.Properties;
import java.util.regex.Pattern;

/**
 * @author kyle on 2022-01-07 8:03 上午
 * 实时热门页面统计改进版， 增强处理乱序数据的Top N排行榜
 */
public class HotPagesPlus {

   public static void main(String[] args) throws Exception {

      // 1. 获取flink stream环境
      StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
      env.setParallelism(1);

      // 2. 读取文件， 转换成POJO
//      URL resource = HotPages.class.getResource("/apache.log");
//      DataStreamSource<String> inputStream = env.readTextFile(resource.getPath());

      // 从kafka读取数据
      Properties properties = new Properties();
      properties.setProperty("bootstrap.servers", "192.168.2.113:9092");
      properties.setProperty("group.id", "flink-hot-pages");
      String topic = "hot_pages";

      FlinkKafkaConsumer<String> stringFlinkKafkaConsumer = new FlinkKafkaConsumer<>(topic, new SimpleStringSchema(), properties);
      DataStreamSource<String> inputStream = env.addSource(stringFlinkKafkaConsumer);


      // 3. 提取时间戳和分配watermark
      SingleOutputStreamOperator<ApacheLogEvent> dataStream = inputStream
              .filter(Strings::isNotBlank)
              .map(line -> {
         String[] fields = line.split(" ");
         SimpleDateFormat simpleDateFormat = new SimpleDateFormat("dd/MM/yyyy:HH:mm:ss");
         Long timestamp = simpleDateFormat.parse(fields[3]).getTime();
         return new ApacheLogEvent(fields[0], fields[1], timestamp, fields[5], fields[6]);
      })
              .assignTimestampsAndWatermarks(WatermarkStrategy.<ApacheLogEvent>forBoundedOutOfOrderness(Duration.ofSeconds(1))
              .withTimestampAssigner(new SerializableTimestampAssigner<ApacheLogEvent>() {
                 @Override
                 public long extractTimestamp(ApacheLogEvent element, long recordTimestamp) {
                    return element.getTimestamp();
                 }
              }));

      dataStream.print("data");

      // 4. 分组开窗聚合
      SingleOutputStreamOperator<PageViewCount> windowAggStream = dataStream
              .filter(data -> "GET".equals(data.getMethod()))   // 过滤get请求
              .filter(data ->{
                 String regex = "^((?!\\.(css|js|png|ico)$).)*$";
                 return Pattern.matches(regex, data.getUrl());
              })
              .keyBy(ApacheLogEvent::getUrl) // 根据url分组
              .window(SlidingEventTimeWindows.of(Time.minutes(10), Time.seconds(5)))
              .allowedLateness(Time.minutes(1))
              .aggregate(new PageCountAgg(), new PageCountResult());

      windowAggStream.print("agg");


      SingleOutputStreamOperator<String> resultStream = windowAggStream
              .keyBy(PageViewCount::getWindowEnd)
              .process(new TopNHotPages(5));


      resultStream.print();

      env.execute();


   }




   // 实现自定义聚合函数
   public static class PageCountAgg implements AggregateFunction<ApacheLogEvent, Long, Long>{

      @Override
      public Long createAccumulator() {
         return 0L;
      }

      @Override
      public Long add(ApacheLogEvent value, Long accumulator) {
         return accumulator + 1;
      }

      @Override
      public Long getResult(Long accumulator) {
         return accumulator;
      }

      @Override
      public Long merge(Long a, Long b) {
         return a+b;
      }
   }


   // 实现自定义的窗口函数
   public static class PageCountResult implements WindowFunction<Long, PageViewCount, String, TimeWindow> {

      @Override
      public void apply(String url, TimeWindow window, java.lang.Iterable<Long> input, Collector<PageViewCount> out) throws Exception {
         out.collect(new PageViewCount(url, window.getEnd(), input.iterator().next()));
      }
   }


   // 实现自定义的处理函数
   public static class TopNHotPages extends KeyedProcessFunction<Long, PageViewCount, String>{

      private Integer topSize;

      public TopNHotPages(Integer topSize) {
         this.topSize = topSize;
      }

      MapState<String, Long> pageViewCountMapState;

      @Override
      public void open(Configuration parameters) throws Exception {
         pageViewCountMapState = getRuntimeContext().getMapState(new MapStateDescriptor<String, Long>("page-view-count-map", String.class, Long.class));

      }

      @Override
      public void processElement(PageViewCount value, Context ctx, Collector<String> out) throws Exception {
         pageViewCountMapState.put(value.getUrl(), value.getCount());
         ctx.timerService().registerEventTimeTimer(value.getWindowEnd() + 1);
         // 注册一个一分钟后的定时器， 用来清空状态
         ctx.timerService().registerEventTimeTimer(value.getWindowEnd() + 60 * 1000L);
      }

      @Override
      public void onTimer(long timestamp, OnTimerContext ctx, Collector<String> out) throws Exception {

         // 先判断是否到了窗口关闭清理时间， 如果是， 直接清空状态返回
         if(timestamp == ctx.getCurrentKey() + 60 * 1000L){
            pageViewCountMapState.clear();
            return;
         }

         ArrayList<Map.Entry<String, Long>> pageViewCounts = Lists.newArrayList(pageViewCountMapState.entries().iterator());

         pageViewCounts.sort(new Comparator<Map.Entry<String, Long>>() {
            @Override
            public int compare(Map.Entry<String, Long> o1, Map.Entry<String, Long> o2) {
               if(o1.getValue() > o2.getValue()){
                  return -1;
               }else if(o1.getValue() < o2.getValue()){
                  return 1;
               }else {
                  return 0;
               }
            }
         });

         // 将排名信息格式化成String， 输出打印
         StringBuilder resultBuilder = new StringBuilder();
         resultBuilder.append("=============================\n");
         resultBuilder.append("窗口结束时间： ").append(new Timestamp(timestamp - 1)).append("\n");

         //遍历列表取 top N
         for(int  i = 0; i < Math.min(topSize, pageViewCounts.size()); i++){
            Map.Entry<String, Long> currentItemViewCount = pageViewCounts.get(i);
            resultBuilder.append("NO ").append(i+1)
                    .append(" 页面url = ").append(currentItemViewCount.getKey())
                    .append(" 浏览量 = ").append(currentItemViewCount.getValue())
                    .append("\n");

         }

         resultBuilder.append("===========================\n");

         // 控制输出频率
         Thread.sleep(1000L);

         out.collect(resultBuilder.toString());


      }
   }


}

~~~

~~~java
// 测试数据 一条条输入kafka
>83.149.9.216 - - 17/05/2015:10:25:49 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:50 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:51 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:52 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:55 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presen
>83.149.9.216 - - 17/05/2015:10:25:57 +0000 GET /presen
>83.149.9.216 - - 17/05/2015:10:26:01 +0000 GET /
>83.149.9.216 - - 17/05/2015:10:26:02 +0000 GET /pre
>83.149.9.216 - - 17/05/2015:10:25:46 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:26:03 +0000 GET /pre
  
// 整合输入和输出，说明处理过程
// 设置的watermark是1秒延迟
// 设置窗口允许延迟1分钟
// 滑动窗口长度是10min，滑动步长是5秒， 即每5秒统计前10分钟的网页浏览量
// 定时器延迟1毫秒

  
>83.149.9.216 - - 17/05/2015:10:25:49 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:50 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:51 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:52 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:55 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:25:56 +0000 GET /presen
>83.149.9.216 - - 17/05/2015:10:25:57 +0000 GET /presen
>83.149.9.216 - - 17/05/2015:10:26:01 +0000 GET /
>83.149.9.216 - - 17/05/2015:10:26:02 +0000 GET /pre
>83.149.9.216 - - 17/05/2015:10:25:46 +0000 GET /presentations
>83.149.9.216 - - 17/05/2015:10:26:03 +0000 GET /pre

data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829549000, method='GET', url='/presentations'}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829550000, method='GET', url='/presentations'}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829551000, method='GET', url='/presentations'}
agg> PageViewCount{url='/presentations', windowEnd=1431829550000, count=1}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829552000, method='GET', url='/presentations'}
=============================
窗口结束时间： 2015-05-17 10:25:50.0
NO 1 页面url = /presentations 浏览量 = 1
===========================

data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829555000, method='GET', url='/presentations'}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829556000, method='GET', url='/presentations'}
agg> PageViewCount{url='/presentations', windowEnd=1431829555000, count=4}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829556000, method='GET', url='/presen'}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829557000, method='GET', url='/presen'}
=============================
窗口结束时间： 2015-05-17 10:25:55.0
NO 1 页面url = /presentations 浏览量 = 4
===========================

data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829561000, method='GET', url='/'}
agg> PageViewCount{url='/presentations', windowEnd=1431829560000, count=6}
agg> PageViewCount{url='/presen', windowEnd=1431829560000, count=2}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829562000, method='GET', url='/pre'}
=============================
窗口结束时间： 2015-05-17 10:26:00.0
NO 1 页面url = /presentations 浏览量 = 6
NO 2 页面url = /presen 浏览量 = 2
===========================

data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829546000, method='GET', url='/presentations'}
agg> PageViewCount{url='/presentations', windowEnd=1431829560000, count=7}
agg> PageViewCount{url='/presentations', windowEnd=1431829555000, count=5}
agg> PageViewCount{url='/presentations', windowEnd=1431829550000, count=2}
data> ApacheLogEvent{ip='83.149.9.216', userId='-', timestamp=1431829563000, method='GET', url='/pre'}
=============================
窗口结束时间： 2015-05-17 10:25:50.0
NO 1 页面url = /presentations 浏览量 = 2
===========================

=============================
窗口结束时间： 2015-05-17 10:25:55.0
NO 1 页面url = /presentations 浏览量 = 5
===========================

=============================
窗口结束时间： 2015-05-17 10:26:00.0
NO 1 页面url = /presentations 浏览量 = 7
NO 2 页面url = /presen 浏览量 = 2
===========================
~~~













